## שימושים רגישים – איפה להיות זהירים במיוחד

בפרק הקודם דיברנו על פרטיות.  
כאן נתמקד במקרים שבהם **עצם הנושא** רגיש, גם אם אתם שומרים על אנונימיות:

- בריאות נפשית ורגשית,  
- בריאות פיזית ורפואה,  
- החלטות משפטיות וכספיות,  
- יחסים אישיים ומשפחתיים,  
- עבודה עם ילדים ואוכלוסיות פגיעות,  
- החלטות שיש להן השלכות כבדות על חיים של אנשים.

אלה תחומים שבהם טעות אחת קטנה או עצה לא מתאימה  
יכולות לפגוע באדם אמיתי – ולכן ה‑AI צריך להיות **כלי עזר**, לא "מורה דרך ראשי".

---

### מה הבעיה הבסיסית ב‑AI במצבים רגישים?

- ה‑AI רואה רק טקסט – הוא לא מכיר את כל הסיפור, את ההיסטוריה ואת ההקשר הלא‑מילולי.  
- הוא לא יודע בוודאות מי יושבת מולו, מה המצב הרפואי, המשפטי או הנפשי המלא.  
- הוא נוטה להישמע בטוח, גם כשהוא **לא מדויק** (ראו מודול 08 על הזיות והטיות).  
- אין לו אחריות מקצועית, רישיון, או אפשרות לשאת בתוצאות.

לכן:

- תשובה "משכנעת" לא בהכרח שווה תשובה **נכונה** או **מתאימה**.  
- והוא **לא יכול להחליף**: טיפול, אבחון, ייעוץ משפטי או ייעוץ פיננסי מקצועי.

---

### איפה AI כן יכול לעזור בצורה בטוחה יחסית?

בדרך כלל מותר ובטוח יותר להשתמש ב‑AI ל־:

- **הבנה כללית** של מושגים:
  - "תסביר/י בפשטות מה זה CBT."  
  - "מה ההבדל בין פסיכיאטר לפסיכולוג?"
- **ארגון מחשבות**:
  - "עזור/י לי לסדר את המחשבות שלי על מצב שבו אדם מרגיש עומס וחרדה בעבודה,  
    בלי לתת עצות טיפוליות ספציפיות."
- **הכנה לפגישה מקצועית**:
  - "תעזור/י לי לנסח שאלות לפגישה עם הפסיכולוגית שלי על חרדה."  
  - "תציע/י שאלות שכדאי לשאול רופא/ה לפני שינוי טיפול תרופתי."
- **תרגול תקשורת**:
  - סימולציה של שיחה עם בן/בת זוג, עם מנהל/ת, עם צוות – במטרה לתרגל ניסוחים.  
  - תמיד מתוך הבנה שזה *אימון בשיחה*, לא ייעוץ זוגי/ניהולי רשמי.

בכל המקרים האלה:

- אתם נשארים בעלי שיקול הדעת,  
- וההחלטות החשובות מתקבלות עם בני אדם אמיתיים.

---

### איפה AI *לא* מספיק – ואסור להסתמך עליו לבד

יש מצבים שבהם חשוב במיוחד **לא** לתת ל‑AI להיות "הדמות הראשית":

- אבחון או טיפול במצוקה נפשית, דיכאון, אובדנות, טראומה.  
- החלטות על תרופות, מינונים, טיפולים רפואיים.  
- החלטות משפטיות עם השלכות אמיתיות (חוזים, גירושין, אחריות פלילית וכו').  
- החלטות כספיות גדולות (חובות, משכנתא, השקעות משמעותיות).  
- החלטות שמשפיעות על אדם אחר שלא נמצא בשיחה (מטופל, תלמיד, בן משפחה).  
- כל מצב שבו יש **סיכון לפגיעה בכם או במישהו אחר**.

במצבים כאלה:

- אפשר להשתמש ב‑AI כדי להבין מושגים, לנסח שאלות,  
  אבל **לא** כדי לקבל החלטה סופית או "אבחנה".

---

### דוגמאות לפי תחום

#### 1. בריאות נפשית ורגשית

אפשרי (זהיר):

- "תסביר/י במילים פשוטות מה ההבדל בין לחץ 'רגיל' לבין חרדה."  
- "תעזור/י לי להוציא מייל מסודר למטפל/ת, שמסביר איך אני מרגיש/ה בזמן האחרון."  
- "תציע/י לי שאלות לשאול פסיכולוגית בפגישה הקרובה לגבי חוסר שינה."

לא מתאים:

- "תאבחן/י אותי – האם יש לי דיכאון?"  
- "תגיד/י לי אם אני צריך/ה טיפול או תרופות."  
- "תן/י לי הנחיות מה לעשות אם אני מרגיש/ה שאני מסוכן/ת לעצמי."

במצבי חירום, מצוקה קשה, או מחשבות על פגיעה בעצמי/באחר –  
פונים **ישירות** לעזרה אנושית (מרכזי חירום, אנשי מקצוע, מוקדי חירום) – **לא** ל‑AI.

---

#### 2. בריאות פיזית ורפואה

אפשרי:

- "תסביר/י מה המשמעות הכללית של האבחנה [שם כללי, בלי פרטים מזהים]."  
- "מה ההבדל העקרוני בין אנטיביוטיקה לווירוס לבין אנטיביוטיקה לחיידקים?"  
- "תעזור/י לי להבין את המושגים שמופיעים בבדיקת דם, ברמה כללית."

לא מתאים:

- "הנה תוצאות בדיקות הדם שלי – תגיד/י לי אם יש לי מחלה."  
- "תכתוב/י לי תוכנית טיפולית במקום הרופא."  
- "האם כדאי לי לשנות מינון של תרופה מסוימת?"

החלטות רפואיות מתקבלות עם רופא/ה או צוות רפואי מוסמך,  
גם אם ה‑AI עזר לכם להבין את השאלות טוב יותר.

---

#### 3. משפט וכספים

אפשרי:

- "תסביר/י בשפה פשוטה מה זה 'כוח קנייה' או 'ריבית דריבית'."  
- "תעזור/י לי להבין ברמה כללית מה ההבדל בין חוזה עבודה רגיל לחוזה פרילנס."  
- "תציע/י רשימת שאלות שכדאי לשאול עו"ד לפני חתימה על חוזה שכירות."

לא מתאים:

- "יש לי חוב של X ₪ – תכתוב/י לי תוכנית יציאה מדויקת בלי יועץ מקצועי."  
- "תמליץ/י לי איפה להשקיע סכום כסף גדול."  
- "תגיד/י לי אם כדאי לי לחתום על החוזה הזה."

כאן טעות אחת יכולה לעלות ביוקר – עדיף שה‑AI יהיה **מסביר**, לא **מחליט**.

---

#### 4. יחסים אישיים ואנשים אחרים

אפשרי:

- "תעזור/י לי לנסח הודעה לבן/בת הזוג על זה שקשה לי, בצורה רגועה ומכבדת."  
- "תן/י לי רעיונות איך לפתוח שיחה רגישה עם חבר/ה על קונפליקט שהיה."  
- "תעזור/י לי לראות את המצב גם מהזווית של האדם השני, ברמה כללית."

לא מתאים:

- "תאבחן/י אם בן/בת הזוג שלי 'נרקיסיסט/ית' על בסיס הטקסט שאני כותב/ת."  
- "תאמר/י לי אם להיפרד מבין/בת הזוג."  
- "תעזור/י לי 'להפיל בפח' מישהו בלי שהוא ישים לב."

השימוש הרצוי הוא **לשפר תקשורת**, לא לשלוט באנשים אחרים או לאבחן אותם.

---

#### 5. ילדים ואוכלוסיות פגיעות

כאשר יש מעורבות של:

- ילדים ובני נוער,  
- אנשים עם מוגבלויות,  
- מטופלים במצוקה חריפה,

הכללים הופכים עוד יותר מחמירים:

- לא כותבים פרטים שמזהים אותם (ראו פרק 01 על פרטיות).  
- לא מבקשים מה‑AI להחליף הדרכה, פיקוח או סמכות מקצועית.  
- כן אפשר לבקש עזרה בניסוח:
  - דף מידע להורים,  
  - הסבר מותאם גיל (ברמה כללית),  
  - שאלות להביא לפגישה עם אנשי מקצוע.

---

### רמזור שימושים רגישים – ירוק / צהוב / אדום

כדי לעשות סדר, אפשר לחשוב על **רמזור**:

**ירוק – לרוב בסדר**  
שאלות ללמידה כללית, הבנת מושגים, ארגון מחשבות.

דוגמאות:

- "תסביר/י בפשטות מה זה התקף חרדה."  
- "תעזור/י לי להבין מה ההבדל בין עורך דין פלילי לעורך דין אזרחי."  
- "תסכם/י לי מאמר כללי (אחרי שהסתרתי פרטים מזהים)."

**צהוב – צריך זהירות וניסוח מדויק**  
שימוש ב‑AI כהכנה לפגישה, או לעיבוד מצב רגיש – בלי לבקש אבחון או החלטה.

דוגמאות:

- "תעזור/י לי לנסח 5 שאלות לפגישה עם הפסיכולוגית על חרדה."  
- "תעזור/י לי לסדר את המחשבות על מצב כלכלי לחוץ, בלי לתת עצות ספציפיות."  
- "תציע/י ניסוח למייל לרופא/ה שבו אני מתאר/ת תסמינים שכדאי לבדוק."

**אדום – לא עושים עם AI**  
בקשות לקבלת אבחנה, החלטות טיפוליות, הנחיות מסוכנות, או החלטות כבדות במקום איש מקצוע.

דוגמאות:

- "תאבחן/י אותי ותגיד/י לי איזה טיפול מתאים לי."  
- "תאמר/י לי אם לפנות למשטרה על אדם מסוים על בסיס מה שאני כותב/ת כאן."  
- "תגיד/י לי אם לחתום על חוזה מסוים או לקחת משכנתא מסוימת."

במקרים האדומים – ה‑AI יכול אולי לעזור לנסח את השאלות,  
אבל מי שעונה הוא **איש מקצוע אנושי**.

---

### מתי חייבים לערב בן אדם אמיתי?

כלל פשוט:

אם השאלה נוגעת ל־

- סיכון לפגיעה בכם או באחר,  
- מצוקה נפשית קשה ומתמשכת,  
- החלטה רפואית או תרופתית,  
- החלטה משפטית/כספית בעלת השלכות גדולות,  
- גורל של אדם אחר שתלוי בכם (בן/בת זוג, ילד, מטופל, תלמיד),

זה רגע שבו **אי אפשר להסתפק ב‑AI**:

- פונים לרופא/ה, פסיכולוג/ית, עו"ד, יועץ/ת פיננסי/ת או דמות מקצועית אחרת.  
- ה‑AI יכול לעזור לכם להתכונן,  
  אבל לא להחליף את האדם שמולכם.

---

### תרגיל – להפוך שימוש רגיש לבטוח יותר

1. חשבו על **שלושה פרומפטים** אמיתיים שהייתם אולי רוצים לשאול AI  
   בתחומים רגישים (רגשי, רפואי, משפטי, כספי, יחסים).
2. סווגו כל אחד לפי הרמזור:
   - ירוק – מידע כללי / הבנת מושגים.  
   - צהוב – הכנה לפגישה / ארגון מחשבות.  
   - אדום – בקשה להחלטה, אבחנה או הנחיה מסוכנת.
3. אם משהו יצא צהוב או אדום – נסו לנסח אותו מחדש כך שיהיה:
   - יותר כללי,  
   - יותר לימודי,  
   - בלי פרטים מזהים,  
   - בלי בקשה להחלטה סופית.
4. אם תרצו – תוכלו לבקש גם מה‑AI עצמו:

> "תעזור/י לי לבדוק אם הפרומפט הזה בטוח ומתאים לשימוש ב‑AI,  
> ולהציע ניסוח בטוח יותר אם צריך."

כך תתרגלו לא רק את התוכן,  
אלא גם את **העמדה האתית** שלכם כמי שעובדים עם AI בתחומים רגישים.

